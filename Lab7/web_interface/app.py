# web_interface/app.py
from flask import Flask, render_template, request, jsonify
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from indexing.index_builder import IndexBuilder
from text_preprocessing.preprocessor_factory import PreprocessorFactory
from vector_storage.chroma_storage import ChromaStorage


class SearchApp:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤—ã–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º"""

    def __init__(self):
        self.app = Flask(__name__)
        self.app.config['SECRET_KEY'] = 'search-system-secret-key'
        self.index_builder = None
        self.preprocessor = None
        self.is_loaded = False

        self.setup_routes()
        self.load_search_system()

    def load_search_system(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""
        try:
            print("–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã...")

            # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            self.preprocessor = PreprocessorFactory.create_lemmatization_preprocessor()

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å
            self.index_builder = IndexBuilder(use_vector_db=True)

            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å
            try:
                self.index_builder.vocabulary.load_vocabulary("search_index/vocabulary.json")
                self.index_builder.vector_storage = ChromaStorage()
                self.index_builder.tfidf_calculator = None  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º
                from indexing.tfidf_calculator import TFIDFCalculator
                self.index_builder.tfidf_calculator = TFIDFCalculator(self.index_builder.vocabulary)
                self.is_loaded = True
                print("‚úÖ –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å: {e}")
                self.is_loaded = False

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            self.is_loaded = False

    def setup_routes(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤ Flask"""

        @self.app.route('/')
        def index():
            """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –ø–æ–∏—Å–∫–æ–º"""
            total_docs = 0
            if self.index_builder and self.index_builder.vector_storage:
                total_docs = self.index_builder.vector_storage.get_document_count()

            return render_template('index.html',
                                   system_loaded=self.is_loaded,
                                   total_documents=total_docs)

        @self.app.route('/search', methods=['POST'])
        def search():
            """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
            if not self.is_loaded:
                return jsonify({'error': '–ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}), 500

            try:
                # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø—Ä–æ—Å –∏–∑ —Ñ–æ—Ä–º—ã
                query = request.form.get('query', '').strip()
                top_k = int(request.form.get('top_k', 10))
                show_analysis = request.form.get('show_analysis', 'false') == 'true'

                if not query:
                    return jsonify({'error': '–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å'}), 400

                print(f"–ü–æ–∏—Å–∫ –∑–∞–ø—Ä–æ—Å–∞: '{query}'")

                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
                results = self.index_builder.search(query, self.preprocessor, top_k=top_k)

                # –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                query_analysis = None
                if show_analysis:
                    query_analysis = self.index_builder.analyze_query(query, self.preprocessor)

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                formatted_results = []
                for result in results:
                    formatted_results.append({
                        'doc_id': result['metadata']['doc_id'],
                        'title': result['metadata']['title'],
                        'snippet': self._generate_snippet(result['snippet'], query),
                        'relevance': round(result['similarity_score'] * 100, 1),
                        'file_type': result['metadata']['file_type'],
                        'date_created': result['metadata']['date_created'],
                        'file_path': result['metadata']['file_path'],
                        'query_terms_in_doc': self._find_query_terms(query, result['snippet'])
                    })

                response_data = {
                    'query': query,
                    'total_found': len(results),
                    'results': formatted_results
                }

                if query_analysis:
                    response_data['query_analysis'] = query_analysis

                return jsonify(response_data)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
                return jsonify({'error': f'–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}'}), 500

        @self.app.route('/analyze-query', methods=['POST'])
        def analyze_query():
            """–ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –±–µ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞"""
            if not self.is_loaded:
                return jsonify({'error': '–ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}), 500

            try:
                query = request.form.get('query', '').strip()
                if not query:
                    return jsonify({'error': '–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å'}), 400

                analysis = self.index_builder.analyze_query(query, self.preprocessor)
                return jsonify(analysis)

            except Exception as e:
                return jsonify({'error': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}'}), 500

        @self.app.route('/stats')
        def stats():
            """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
            if not self.is_loaded:
                return jsonify({'error': '–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}), 500

            stats = self.index_builder.get_index_statistics()
            return jsonify(stats)

        @self.app.route('/health')
        def health():
            """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
            total_docs = 0
            if self.index_builder and self.index_builder.vector_storage:
                total_docs = self.index_builder.vector_storage.get_document_count()

            return jsonify({
                'status': 'ready' if self.is_loaded else 'loading',
                'documents_loaded': total_docs
            })

        @self.app.route('/debug-query', methods=['POST'])
        def debug_query():
            """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
            if not self.is_loaded:
                return jsonify({'error': '–ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}), 500

            try:
                query = request.form.get('query', '').strip()
                if not query:
                    return jsonify({'error': '–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å'}), 400

                # –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞
                analysis = self.index_builder.tfidf_calculator.debug_query_processing(query, self.preprocessor)

                return jsonify({
                    'query': query,
                    'debug_info': '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Å–æ–ª—å —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏'
                })

            except Exception as e:
                return jsonify({'error': f'–û—à–∏–±–∫–∞ –æ—Ç–ª–∞–¥–∫–∏: {str(e)}'}), 500

        @self.app.route('/vocabulary-stats')
        def vocabulary_stats():
            """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–≤–∞—Ä—è"""
            if not self.is_loaded:
                return jsonify({'error': '–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}), 500

            vocab = self.index_builder.vocabulary
            stats = vocab.get_statistics()

            # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Ä–º–∏–Ω–æ–≤
            sample_terms = list(vocab.term_to_index.keys())[:50]

            return jsonify({
                'vocabulary_size': stats['vocabulary_size'],
                'total_documents': stats['total_documents'],
                'sample_terms': sample_terms,
                'most_frequent_terms': stats['most_frequent_terms'][:20]
            })

    def _generate_snippet(self, text: str, query: str, max_length: int = 200) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–Ω–∏–ø–ø–µ—Ç–∞ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π –∑–∞–ø—Ä–æ—Å–∞"""
        if not text:
            return ""

        query_terms = query.lower().split()
        text_lower = text.lower()

        # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –ª—é–±–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞
        best_position = len(text)
        for term in query_terms:
            pos = text_lower.find(term)
            if pos != -1 and pos < best_position:
                best_position = pos

        # –í—ã—Ä–µ–∑–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –≤–æ–∫—Ä—É–≥ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
        start = max(0, best_position - 50)
        end = min(len(text), start + max_length)

        snippet = text[start:end]

        # –î–æ–±–∞–≤–ª—è–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω
        if start > 0:
            snippet = "..." + snippet
        if end < len(text):
            snippet = snippet + "..."

        # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Ç–µ—Ä–º–∏–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
        for term in query_terms:
            snippet = self._highlight_term(snippet, term)

        return snippet

    def _highlight_term(self, text: str, term: str) -> str:
        """–ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Ç–µ—Ä–º–∏–Ω–∞ –≤ —Ç–µ–∫—Å—Ç–µ"""
        import re
        pattern = re.compile(re.escape(term), re.IGNORECASE)
        return pattern.sub(f'<mark>{term}</mark>', text)

    def _find_query_terms(self, query: str, text: str) -> list:
        """–ü–æ–∏—Å–∫ —Ç–µ—Ä–º–∏–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Ç–µ–∫—Å—Ç–µ"""
        query_terms = set(query.lower().split())
        text_terms = set(text.lower().split())
        return list(query_terms & text_terms)

    def run(self, host='127.0.0.1', port=5000, debug=True):
        """–ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞"""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –Ω–∞ http://{host}:{port}")
        if self.is_loaded:
            total_docs = self.index_builder.vector_storage.get_document_count()
            print(f"üìä –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –ø–æ–∏—Å–∫—É! –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {total_docs}")
        else:
            print("‚ö†Ô∏è  –°–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞.")

        self.app.run(host=host, port=port, debug=debug)