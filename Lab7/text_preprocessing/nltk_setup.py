import nltk

def download_nltk_resources():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã NLTK –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ"""
    resources = [
        'tokenizers/punkt_tab',
        'corpora/stopwords',
        'corpora/wordnet',
        'taggers/averaged_perceptron_tagger'
    ]
    
    for resource in resources:
        try:
            nltk.data.find(resource)
            print(f"‚úì –†–µ—Å—É—Ä—Å {resource} —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except LookupError:
            print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ—Å—É—Ä—Å–∞ {resource}...")
            resource_name = resource.split('/')[-1]
            nltk.download(resource_name)
            print(f"‚úì –†–µ—Å—É—Ä—Å {resource} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
download_nltk_resources()