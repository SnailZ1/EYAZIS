# vector_storage/chroma_storage.py
import chromadb
from typing import List, Dict, Any
import numpy as np
from .base_storage import VectorStorage


class ChromaStorage(VectorStorage):
    """Ð’ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ChromaDB"""

    def __init__(self, collection_name: str = "document_search", persist_directory: str = "./chroma_db"):
        self.client = chromadb.PersistentClient(path=persist_directory)
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"description": "Document search system with TF-IDF vectors"}
        )
        self.persist_directory = persist_directory

    def store_documents(self, documents: List, tfidf_vectors: Dict[int, List[float]]) -> None:
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¸ Ð¸Ñ… Ð²ÐµÐºÑ‚Ð¾Ñ€Ñ‹ Ð² ChromaDB"""
        print("Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð² Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½ÑƒÑŽ Ð‘Ð”...")

        ids = []
        embeddings = []
        metadatas = []
        documents_text = []

        for doc in documents:
            doc_id = str(doc.doc_id)
            vector = tfidf_vectors.get(doc.doc_id)

            if vector is None:
                continue

            # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð² numpy array Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ð´Ð»Ñ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ð³Ð¾ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð°
            vector_np = np.array(vector, dtype=np.float32)
            norm = np.linalg.norm(vector_np)
            if norm > 0:
                vector_np = vector_np / norm

            ids.append(doc_id)
            embeddings.append(vector_np.tolist())

            metadata = {
                "doc_id": doc.doc_id,
                "title": doc.title,
                "file_path": doc.file_path,
                "file_type": doc.file_type,
                "date_created": doc.date_created,
                "date_added": doc.date_added,
                "content_length": len(doc.content),
                "processed_length": len(doc.processed_content) if hasattr(doc, 'processed_content') else 0
            }
            metadatas.append(metadata)

            documents_text.append(doc.processed_content if hasattr(doc, 'processed_content') else doc.content[:500])

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸ÑŽ
        if ids:
            self.collection.add(
                ids=ids,
                embeddings=embeddings,
                metadatas=metadatas,
                documents=documents_text
            )
            print(f"âœ… Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½ÑƒÑŽ Ð‘Ð”: {len(ids)}")
        else:
            print("âŒ ÐÐµÑ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ")

    def search_similar(self, query_vector: List[float], top_k: int = 10) -> List[Dict]:
        """ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¿Ð¾ Ð²ÐµÐºÑ‚Ð¾Ñ€Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        if not query_vector or all(x == 0 for x in query_vector):
            print("âŒ Ð—Ð°Ð¿Ñ€Ð¾ÑÐ½Ñ‹Ð¹ Ð²ÐµÐºÑ‚Ð¾Ñ€ Ð½ÑƒÐ»ÐµÐ²Ð¾Ð¹ - Ð½ÐµÑ‚ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÑŽÑ‰Ð¸Ñ… Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð²")
            return []

        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ query vector Ð´Ð»Ñ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ð³Ð¾ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð°
        query_np = np.array(query_vector, dtype=np.float32)
        query_norm = np.linalg.norm(query_np)
        if query_norm > 0:
            query_np = query_np / query_norm
        else:
            print("âŒ ÐÐ¾Ñ€Ð¼Ð° query vector Ñ€Ð°Ð²Ð½Ð° 0")
            return []

        print(f"ðŸ” ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾ Ð²ÐµÐºÑ‚Ð¾Ñ€Ñƒ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸ {len(query_vector)}")
        print(f"ðŸ“ ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ query vector: {query_norm:.4f}")

        try:
            results = self.collection.query(
                query_embeddings=[query_np.tolist()],
                n_results=min(top_k, self.collection.count()),
                include=["metadatas", "distances", "documents"]
            )

            formatted_results = []
            if results['ids'] and results['ids'][0]:
                print(f"âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²: {len(results['ids'][0])}")

                for i, doc_id in enumerate(results['ids'][0]):
                
                    distance = results['distances'][0][i]
                    similarity = abs(distance / 2 - 1)  # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð² ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾

                    if not round(similarity, 1): continue

                    formatted_results.append({
                        'doc_id': int(doc_id),
                        'metadata': results['metadatas'][0][i],
                        'similarity_score': similarity,
                        'distance': distance,
                        'snippet': results['documents'][0][i][:300] if results['documents'][0][i] else ""
                    })

                    print(f"   ðŸ“„ {results['metadatas'][0][i]['title']}: similarity={similarity:.4f}")
            else:
                print("âŒ Chroma Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ»Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²")

            return formatted_results

        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ° Ð² Chroma: {e}")
            return []

    def get_document_count(self) -> int:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ"""
        return self.collection.count()

    def clear_storage(self) -> None:
        """ÐžÑ‡Ð¸Ñ‰Ð°ÐµÑ‚ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ"""
        self.client.delete_collection(self.collection.name)
        self.collection = self.client.get_or_create_collection(
            name=self.collection.name,
            metadata={"description": "Document search system with TF-IDF vectors"}
        )

    def get_collection_info(self) -> Dict:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸"""
        return {
            "name": self.collection.name,
            "document_count": self.get_document_count(),
            "persist_directory": self.persist_directory
        }