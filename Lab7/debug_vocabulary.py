# debug_vocabulary.py
# !/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–∫–∞ —Å–ª–æ–≤–∞—Ä—è –∏ –ø–æ–∏—Å–∫–∞ —Ç–µ—Ä–º–∏–Ω–æ–≤
"""

import sys
import os
import json

sys.path.append(os.path.dirname(os.path.abspath(__file__)))


def debug_vocabulary():
    """–û—Ç–ª–∞–¥–∫–∞ —Å–ª–æ–≤–∞—Ä—è"""
    print("=== –û–¢–õ–ê–î–ö–ê –°–õ–û–í–ê–†–Ø ===")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å
        with open('search_index/vocabulary.json', 'r', encoding='utf-8') as f:
            vocab_data = json.load(f)

        term_to_index = vocab_data['term_to_index']
        print(f"–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(term_to_index)} —Ç–µ—Ä–º–∏–Ω–æ–≤")

        # –ò—â–µ–º —Ç–µ—Ä–º–∏–Ω—ã —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å read
        print("\nüîç –ü–æ–∏—Å–∫ —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å 'read':")
        read_terms = [term for term in term_to_index.keys() if 'read' in term.lower()]
        for term in read_terms:
            idx = term_to_index[term]
            df = vocab_data['term_document_frequency'][term]
            print(f"  '{term}': –∏–Ω–¥–µ–∫—Å={idx}, –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤={df}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ç–µ—Ä–º–∏–Ω–æ–≤
        print(f"\nüìö –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ:")
        sample_terms = list(term_to_index.keys())[:30]
        for i, term in enumerate(sample_terms):
            print(f"  {i + 1:2d}. '{term}'")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == '__main__':
    debug_vocabulary()