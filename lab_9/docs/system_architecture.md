# Архитектура системы автоматического реферирования

## Общая структура

Система построена по модульному принципу и состоит из следующих компонентов:

```
┌─────────────────────────────────────────────────────────────┐
│                    GUI (gui.py)                              │
│  - Интерфейс пользователя                                   │
│  - Управление потоком работы                                │
└────────────┬────────────────────────────────────────────────┘
             │
             ├──────────────┬──────────────┬──────────────┐
             │              │              │              │
             ▼              ▼              ▼              ▼
┌─────────────────┐ ┌──────────────┐ ┌─────────────┐ ┌──────────────┐
│ TextProcessor   │ │ Summarizer   │ │ OSTIS       │ │ Knowledge    │
│                 │ │              │ │ Integration │ │ Base         │
│ - Токенизация  │ │ - TF-IDF     │ │             │ │              │
│ - Определение  │ │ - Extraction │ │ - SCs Gen   │ │ - Термины    │
│   языка        │ │ - Keywords   │ │ - Semantic  │ │ - Связи      │
│ - Фильтрация   │ │              │ │   Links     │ │              │
└─────────────────┘ └──────────────┘ └─────────────┘ └──────────────┘
```

## Компоненты системы

### 1. GUI (gui.py)

**Назначение**: Графический интерфейс пользователя

**Основные классы**:
- `SummarizerGUI` - главное окно приложения

**Функциональность**:
- Загрузка документов
- Отображение исходного текста
- Настройка параметров (домен, количество предложений)
- Отображение результатов (реферат, ключевые слова, SC-код)
- Сохранение и печать

**Технологии**: Tkinter (встроенная библиотека Python)

### 2. TextProcessor (text_processor.py)

**Назначение**: Предобработка текста

**Основные классы**:
- `TextProcessor` - обработка и токенизация текста

**Функциональность**:
- Определение языка (langdetect)
- Разбиение на предложения с сохранением позиции
- Токенизация слов
- Фильтрация:
  - Стоп-слова (из файлов stopwords_ru.txt, stopwords_en.txt)
  - Числа
  - Латиница в русском тексте
  - Короткие слова (< 3 символов)
- Вычисление позиционных весов

**Алгоритмы**:
- Регулярные выражения для токенизации
- Позиционное взвешивание (первые/последние абзацы важнее)

### 3. Summarizer (summarizer.py)

**Назначение**: Ядро системы реферирования

**Основные классы**:
- `TFIDFCalculator` - вычисление TF-IDF
- `SentenceExtractor` - извлечение предложений
- `KeywordExtractor` - извлечение ключевых слов

**Функциональность**:

#### TFIDFCalculator
- Вычисление TF (Term Frequency)
- Вычисление IDF (Inverse Document Frequency)
- Комбинирование в TF-IDF

#### SentenceExtractor
- Извлечение N наиболее информативных предложений
- Взвешивание на основе:
  - TF-IDF слов в предложении
  - Позиции в документе
  - Позиции в абзаце
  - Длины предложения
- Сохранение исходного порядка предложений

#### KeywordExtractor
- Извлечение ключевых терминов
- Построение иерархического дерева
- Использование базы знаний для группировки

### 4. OSTIS Integration (ostis_integration.py)

**Назначение**: Интеграция с OSTIS, генерация SC-кода

**Основные классы**:
- `SCsGenerator` - генератор SC-кода
- `SemanticLinker` - создание семантических связей

**Функциональность**:

#### SCsGenerator
- Генерация SCs-файлов
- Создание узлов для:
  - Документов
  - Рефератов
  - Предложений
  - Ключевых слов
- Установление связей (nrel_summary, nrel_includes, nrel_key_concept)

#### SemanticLinker
- Поиск семантических связей между терминами
- Типы связей:
  - `nrel_related_term` - связанные термины
  - `nrel_synonym` - синонимы
- Улучшение извлечения ключевых слов через семантику

### 5. Knowledge Base (knowledge_base.py)

**Назначение**: База знаний предметных областей

**Структура**:
```python
KNOWLEDGE_BASE = {
    "medical": {
        "ru": {термин: [связанные_термины]},
        "en": {термин: [связанные_термины]}
    },
    "art": {
        "ru": {термин: [связанные_термины]},
        "en": {термин: [связанные_термины]}
    }
}
```

**Использование**:
- Группировка ключевых слов
- Усиление веса доменных терминов
- Построение иерархии терминов
- Генерация семантических связей

## Поток данных

### 1. Загрузка документа

```
Пользователь → GUI.load_document()
                    ↓
                Чтение файла
                    ↓
                Сохранение в self.current_text
                    ↓
                TextProcessor.detect_language()
                    ↓
                Отображение в GUI
```

### 2. Генерация реферата

```
Пользователь → GUI.generate_summary()
                    ↓
                SentenceExtractor.extract_summary()
                    ├→ TextProcessor.tokenize_sentences()
                    ├→ TextProcessor.tokenize_words()
                    ├→ TFIDFCalculator.calculate_tfidf()
                    ├→ Вычисление весов предложений
                    └→ Выбор топ-N предложений
                    ↓
                KeywordExtractor.extract_keywords()
                    ├→ TFIDFCalculator.calculate_tfidf()
                    ├→ Усиление через knowledge_base
                    └→ Построение иерархии
                    ↓
                SemanticLinker.enhance_keywords_with_semantics()
                    ↓
                SCsGenerator.generate_document_scs()
                    ↓
                Отображение результатов в GUI
```

### 3. Сохранение результатов

```
Пользователь → GUI.save_summary()
                    ↓
                Сохранение трех файлов:
                    ├→ реферат.txt
                    ├→ реферат_keywords.txt
                    └→ реферат.scs
```

## Взаимодействие компонентов

### Зависимости

- **GUI** зависит от всех остальных компонентов
- **Summarizer** зависит от TextProcessor и KnowledgeBase
- **OSTIS Integration** зависит от KnowledgeBase
- **TextProcessor** независим
- **KnowledgeBase** независим

### Расширяемость

Система спроектирована для легкого расширения:

1. **Добавление языков**: 
   - Добавить файл стоп-слов
   - Обновить knowledge_base.py

2. **Добавление предметных областей**:
   - Расширить KNOWLEDGE_BASE в knowledge_base.py

3. **Новые алгоритмы реферирования**:
   - Создать новый класс, наследующий интерфейс SentenceExtractor

4. **Альтернативные интерфейсы**:
   - CLI: создать cli.py
   - Web: создать web_app.py (Flask/FastAPI)

## Производительность

### Временная сложность

- **Токенизация**: O(n), где n - длина текста
- **TF-IDF**: O(m × k), где m - количество предложений, k - средняя длина
- **Сортировка предложений**: O(m log m)
- **Общая сложность**: O(n + m × k + m log m)

### Оптимизации

- Кэширование IDF для повторных вычислений
- Ленивая загрузка стоп-слов
- Эффективное использование регулярных выражений

### Масштабируемость

Система эффективно обрабатывает документы размером до 50 страниц.
Для больших документов рекомендуется:
- Разбиение на главы
- Параллельная обработка секций
- Использование более эффективных структур данных

## Безопасность и надежность

### Обработка ошибок

- Проверка существования файлов
- Валидация входных данных
- Обработка исключений при токенизации
- Fallback для определения языка

### Логирование

В текущей версии используется базовое логирование через print.
Для production рекомендуется:
- Модуль logging
- Ротация логов
- Уровни логирования (DEBUG, INFO, WARNING, ERROR)
