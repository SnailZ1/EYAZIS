# check_processed_docs.py
# !/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from documents_processing.collector import DocumentCollector
from text_preprocessing.preprocessor_factory import PreprocessorFactory


def check_processed_docs():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    print("=== –ü–†–û–í–ï–†–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –î–û–ö–£–ú–ï–ù–¢–û–í ===")

    collector = DocumentCollector()
    documents = collector.collect_documents("docs")

    preprocessor = PreprocessorFactory.create_lemmatization_preprocessor()

    print(f"üìö –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
    for i, doc in enumerate(documents[:5]):  # –ü–µ—Ä–≤—ã–µ 5 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        print(f"\n--- –î–æ–∫—É–º–µ–Ω—Ç {i + 1}: {doc.title} ---")
        print(f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(doc.content)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        processed = preprocessor.preprocess_text(doc.content, return_string=True)
        doc.processed_content = processed

        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(processed)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {processed[:200]}...")

        # –ò—â–µ–º —Ç–µ—Ä–º–∏–Ω—ã related to read
        if 'read' in processed:
            print("‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç 'read'")
        else:
            print("‚ùå –ù–µ —Å–æ–¥–µ—Ä–∂–∏—Ç 'read'")


if __name__ == '__main__':
    check_processed_docs()